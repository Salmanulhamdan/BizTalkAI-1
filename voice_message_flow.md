# Voice Message Flow in BizTalkAI

## Complete User Voice Message Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           VOICE MESSAGE FLOW                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. USER INITIATES VOICE SESSION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ User clicks green "Call" button in ChatPage or VoiceModal                   â”‚
   â”‚ â†’ Triggers handleCallClick() in ChatPage.tsx (line 107)                     â”‚
   â”‚ â†’ Calls startSession() from useWebRTCVoice hook                             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
2. SESSION SETUP
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ useWebRTCVoice.startSession() (line 116):                                   â”‚
   â”‚                                                                             â”‚
   â”‚ a) Request ephemeral token from /api/session                                â”‚
   â”‚    â†’ Server calls OpenAI's /v1/realtime/sessions                            â”‚
   â”‚    â†’ Returns client_secret for authentication                               â”‚
   â”‚                                                                             â”‚
   â”‚ b) Request microphone permission                                            â”‚
   â”‚    â†’ navigator.mediaDevices.getUserMedia()                                  â”‚
   â”‚    â†’ Audio config: echoCancellation, noiseSuppression, autoGainControl      â”‚
   â”‚                                                                             â”‚
   â”‚ c) Create RTCPeerConnection                                                 â”‚
   â”‚    â†’ Add local audio stream to peer connection                              â”‚
   â”‚    â†’ Create data channel for events                                         â”‚
   â”‚                                                                             â”‚
   â”‚ d) Send session configuration via data channel                              â”‚
   â”‚    â†’ Company-specific instructions                                          â”‚
   â”‚    â†’ Voice settings, audio formats, transcription models                    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
3. WEBRTC CONNECTION ESTABLISHMENT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ a) Create SDP offer                                                         â”‚
   â”‚ b) Send offer to OpenAI Realtime API                                        â”‚
   â”‚    â†’ POST https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview  â”‚
   â”‚ c) Receive SDP answer from OpenAI                                           â”‚
   â”‚ d) Set remote description                                                   â”‚
   â”‚ e) Connection established, status = "connected"                             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
4. USER SPEAKS (VOICE INPUT)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ User speaks into microphone                                                 â”‚
   â”‚                                                                             â”‚
   â”‚ DUAL AUDIO PROCESSING:                                                      â”‚
   â”‚                                                                             â”‚
   â”‚ Path A - Real-time Streaming (AI Processing Only):                          â”‚
   â”‚ â†’ Audio stream sent via WebRTC to OpenAI                                    â”‚
   â”‚ â†’ OpenAI processes audio for AI responses                                   â”‚
   â”‚ â†’ Server-side VAD detects speech start/stop                                 â”‚
   â”‚ â†’ Threshold: 0.5, Silence duration: 500ms                                  â”‚
   â”‚ â†’ NO user transcription (disabled to avoid duplicates)                      â”‚
   â”‚                                                                             â”‚
   â”‚ Path B - Local Whisper Transcription (User Speech Only):                    â”‚
   â”‚ â†’ MediaRecorder captures audio chunks (100ms intervals)                     â”‚
   â”‚ â†’ Local silence detection (2s threshold)                                    â”‚
   â”‚ â†’ Audio chunks sent to /api/whisper/transcribe                              â”‚
   â”‚ â†’ OpenAI Whisper API transcribes locally                                    â”‚
   â”‚ â†’ Immediate local transcription feedback for user speech                    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
5. SEPARATED TRANSCRIPTION EVENTS
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ TWO SEPARATE TRANSCRIPTION STREAMS:                                         â”‚
   â”‚                                                                             â”‚
   â”‚ Stream A - OpenAI Realtime Events (AI Responses Only):                      â”‚
   â”‚ â†’ "input_audio_buffer.speech_started" (for VAD only)                       â”‚
   â”‚ â†’ "response.audio_transcript.delta" (AI response transcription)             â”‚
   â”‚ â†’ "response.audio_transcript.done" (AI response completed)                  â”‚
   â”‚ â†’ User transcription events DISABLED to avoid duplicates                    â”‚
   â”‚                                                                             â”‚
   â”‚ Stream B - Local Whisper Events (User Speech Only):                         â”‚
   â”‚ â†’ MediaRecorder.onstop triggers processing                                  â”‚
   â”‚ â†’ Audio blob sent to /api/whisper/transcribe                               â”‚
   â”‚ â†’ OpenAI Whisper API returns transcription                                 â”‚
   â”‚ â†’ onTranscriptionUpdate callback triggered                                  â”‚
   â”‚                                                                             â”‚
   â”‚ Processing in useWebRTCVoice:                                               â”‚
   â”‚ â†’ Only local Whisper calls addTranscriptionMessage() for user speech        â”‚
   â”‚ â†’ Only OpenAI Realtime calls addTranscriptionMessage() for AI responses     â”‚
   â”‚ â†’ Local transcriptions marked with isLocal: true                           â”‚
   â”‚ â†’ Confidence scores included for local transcriptions                       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
6. MESSAGE DISPLAY
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ addTranscriptionMessage() (line 99):                                        â”‚
   â”‚ â†’ Creates TranscriptionMessage object with isLocal flag                     â”‚
   â”‚ â†’ Adds to state.transcription array                                         â”‚
   â”‚ â†’ Logs activity for debugging                                               â”‚
   â”‚                                                                             â”‚
   â”‚ ChatPage.tsx useEffect (lines 77-105):                                     â”‚
   â”‚ â†’ Watches state.transcription changes                                       â”‚
   â”‚ â†’ Converts transcriptions to Message objects                                â”‚
   â”‚ â†’ Adds to messages array for display                                        â”‚
   â”‚ â†’ Messages appear in chat UI with indicators:                               â”‚
   â”‚   â€¢ "AI Response" for OpenAI Realtime AI transcriptions                     â”‚
   â”‚   â€¢ "Local Transcription" for Whisper user transcriptions                   â”‚
   â”‚   â€¢ Confidence percentage for local transcriptions                          â”‚
   â”‚                                                                             â”‚
   â”‚ Visual Indicators:                                                          â”‚
   â”‚ â†’ "Recording your speech..." status when MediaRecorder active               â”‚
   â”‚ â†’ "Transcribing your speech..." status when Whisper processing              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
7. AI RESPONSE GENERATION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ OpenAI processes user's voice input:                                        â”‚
   â”‚ â†’ Transcribes user speech to text                                           â”‚
   â”‚ â†’ Generates AI response using GPT-4o Realtime                               â”‚
   â”‚ â†’ Converts response to speech using selected voice                          â”‚
   â”‚ â†’ Sends audio back via WebRTC                                               â”‚
   â”‚                                                                             â”‚
   â”‚ Response Events:                                                            â”‚
   â”‚ â†’ "response.audio_transcript.delta"                                         â”‚
   â”‚ â†’ "response.audio_transcript.done"                                          â”‚
   â”‚ â†’ "response.done"                                                           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
8. AI RESPONSE DISPLAY & AUDIO
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ AI Response Processing (lines 289-332):                                     â”‚
   â”‚ â†’ Extract transcript from response events                                   â”‚
   â”‚ â†’ Call addTranscriptionMessage("Efa", transcript)                          â”‚
   â”‚ â†’ Display AI message in chat UI                                             â”‚
   â”‚                                                                             â”‚
   â”‚ Audio Playback:                                                             â”‚
   â”‚ â†’ AI audio stream received via WebRTC                                       â”‚
   â”‚ â†’ Set to audioElement.srcObject                                             â”‚
   â”‚ â†’ Auto-plays through user's speakers                                        â”‚
   â”‚ â†’ User hears AI response in real-time                                       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
9. CONTINUOUS CONVERSATION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Process repeats for each voice exchange:                                    â”‚
   â”‚ â†’ User speaks â†’ Transcription â†’ AI processes â†’ AI responds â†’ Audio plays    â”‚
   â”‚                                                                             â”‚
   â”‚ Activity Tracking:                                                          â”‚
   â”‚ â†’ resetActivityTimer() called on any activity                               â”‚
   â”‚ â†’ 8-minute idle timeout prevents runaway costs                              â”‚
   â”‚ â†’ 15-minute hard limit for total session time                               â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
10. SESSION END
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ User clicks red "End Call" button or session times out:                     â”‚
   â”‚                                                                             â”‚
   â”‚ stopSession() cleanup (line 423):                                           â”‚
   â”‚ â†’ Clear all timeout timers                                                  â”‚
   â”‚ â†’ Close RTCPeerConnection                                                   â”‚
   â”‚ â†’ Stop local media stream                                                   â”‚
   â”‚ â†’ Reset audio element                                                       â”‚
   â”‚ â†’ Clear transcription state                                                 â”‚
   â”‚ â†’ Set connection status to "idle"                                           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              KEY COMPONENTS                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“± Frontend Components:
   â€¢ ChatPage.tsx - Main chat interface with voice controls
   â€¢ VoiceModal.tsx - Dedicated voice call interface
   â€¢ useWebRTCVoice.ts - Core WebRTC and voice logic
   â€¢ useLocalWhisper.ts - Local Whisper transcription hook
   â€¢ VoiceVisualizer.tsx - Visual feedback during calls

ğŸ”§ Backend Components:
   â€¢ /api/session - Creates OpenAI Realtime sessions
   â€¢ /api/whisper/transcribe - Local Whisper transcription endpoint
   â€¢ routes.ts - Handles session creation and company instructions
   â€¢ index.ts - Express server setup with multer middleware

ğŸŒ External Services:
   â€¢ OpenAI Realtime API - Voice processing and AI responses
   â€¢ OpenAI Whisper API - Local speech-to-text transcription
   â€¢ WebRTC - Real-time audio streaming

âš™ï¸ Configuration:
   â€¢ Voice: "marin" (default)
   â€¢ Model: "gpt-4o-realtime-preview-2024-10-01"
   â€¢ Audio Format: PCM16 (Realtime), WebM/Opus (Local)
   â€¢ VAD: Server-side with 0.5 threshold, 500ms silence
   â€¢ Local Recording: 100ms chunks, 2s silence threshold, 10s max
   â€¢ Timeouts: 8min idle, 15min hard limit

ğŸ”’ Security & Cost Controls:
   â€¢ Ephemeral tokens for session authentication
   â€¢ Activity-based timeout system
   â€¢ Automatic session cleanup on page unload
   â€¢ Cost safeguards to prevent runaway sessions
